{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-15T12:36:46.563564Z",
     "start_time": "2025-11-15T12:36:46.559516Z"
    }
   },
   "source": [
    "import json\n",
    "import csv\n",
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "BASE_DIR = Path(\"..\").resolve()\n",
    "SRC_DIR = BASE_DIR / \"for_convert\"\n",
    "DST_DIR = BASE_DIR / \"converted_csv\"\n",
    "DST_DIR.mkdir(exist_ok=True)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T12:36:46.582748Z",
     "start_time": "2025-11-15T12:36:46.579475Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def convert_jsonl_to_csv(filename: str):\n",
    "    jsonl_path = SRC_DIR / filename\n",
    "    csv_path = DST_DIR / (Path(filename).stem + \".csv\")\n",
    "\n",
    "    rows = []\n",
    "    with open(jsonl_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            obj = json.loads(line)\n",
    "            rows.append(obj)\n",
    "\n",
    "    if not rows:\n",
    "        print(f\"[JSONL] No rows found in {jsonl_path}\")\n",
    "        return\n",
    "\n",
    "    fieldnames = sorted({k for row in rows for k in row.keys()})\n",
    "\n",
    "    with open(csv_path, \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(rows)\n",
    "\n",
    "    print(f\"[JSONL] {jsonl_path} -> {csv_path}\")"
   ],
   "id": "6d9852786543018a",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T12:36:46.641826Z",
     "start_time": "2025-11-15T12:36:46.635350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def convert_xml_to_csv(filename: str, row_tag: str = \"customer\"):\n",
    "    xml_path = SRC_DIR / filename\n",
    "    csv_path = DST_DIR / (Path(filename).stem + \".csv\")\n",
    "\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    rows = []\n",
    "    for elem in root.findall(row_tag):\n",
    "        row = {}\n",
    "        for child in elem:\n",
    "            row[child.tag] = (child.text or \"\").strip()\n",
    "        rows.append(row)\n",
    "\n",
    "    if not rows:\n",
    "        print(f\"[XML] No <{row_tag}> rows found in {xml_path}\")\n",
    "        return\n",
    "\n",
    "    fieldnames = sorted({k for row in rows for k in row.keys()})\n",
    "\n",
    "    with open(csv_path, \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(rows)\n",
    "\n",
    "    print(f\"[XML] {xml_path} -> {csv_path}\")"
   ],
   "id": "f9f6a4efee00cf8e",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T12:36:46.689295Z",
     "start_time": "2025-11-15T12:36:46.686949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def convert_parquet_to_csv(filename: str):\n",
    "    parquet_path = SRC_DIR / filename\n",
    "    csv_path = DST_DIR / (Path(filename).stem + \".csv\")\n",
    "\n",
    "    df = pd.read_parquet(parquet_path)\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "    print(f\"[PARQUET] {parquet_path} -> {csv_path}\")"
   ],
   "id": "9e3eed2573d959ea",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T12:36:46.745739Z",
     "start_time": "2025-11-15T12:36:46.742823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def convert_excel_to_csv(filename: str, sheet_name=0):\n",
    "    excel_path = SRC_DIR / filename\n",
    "    csv_path = DST_DIR / (Path(filename).stem + \".csv\")\n",
    "\n",
    "    df = pd.read_excel(excel_path, sheet_name=sheet_name)\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "    print(f\"[EXCEL] {excel_path} -> {csv_path}\")"
   ],
   "id": "de068831c948a02e",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T12:36:55.682465Z",
     "start_time": "2025-11-15T12:36:46.789687Z"
    }
   },
   "cell_type": "code",
   "source": [
    "convert_jsonl_to_csv(\"financial_ratios.jsonl\")\n",
    "convert_xml_to_csv(\"geographic_data.xml\", row_tag=\"customer\")\n",
    "convert_parquet_to_csv(\"credit_history.parquet\")\n",
    "convert_excel_to_csv(\"loan_details.xlsx\")"
   ],
   "id": "bf9141806a16aae6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[JSONL] /home/shohruh/Desktop/cbu/for_convert/financial_ratios.jsonl -> /home/shohruh/Desktop/cbu/converted_csv/financial_ratios.csv\n",
      "[XML] /home/shohruh/Desktop/cbu/for_convert/geographic_data.xml -> /home/shohruh/Desktop/cbu/converted_csv/geographic_data.csv\n",
      "[PARQUET] /home/shohruh/Desktop/cbu/for_convert/credit_history.parquet -> /home/shohruh/Desktop/cbu/converted_csv/credit_history.csv\n",
      "[EXCEL] /home/shohruh/Desktop/cbu/for_convert/loan_details.xlsx -> /home/shohruh/Desktop/cbu/converted_csv/loan_details.csv\n"
     ]
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
