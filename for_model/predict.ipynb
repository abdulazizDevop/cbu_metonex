{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d2b1d912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# YANGI DATASET UCHUN PREDICT QILISH\n",
    "# ============================================\n",
    "# Bu notebook saqlangan modelni yuklab, yangi dataset uchun predict qilish uchun\n",
    "# (default ustuni bo'lmagan dataset uchun)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d837c856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 1. SAQLANGAN MODEL VA ENCODERLARNI YUKLASH\n",
    "# ============================================\n",
    "\n",
    "model_folder = Path('../result')\n",
    "\n",
    "# Model fayl yo'llari\n",
    "model_file = model_folder / 'trained_model.pkl'\n",
    "encoders_file = model_folder / 'label_encoders.pkl'\n",
    "categorical_file = model_folder / 'categorical_columns.pkl'\n",
    "feature_columns_file = model_folder / 'feature_columns.pkl'\n",
    "\n",
    "# Tekshirish: fayllar mavjudmi?\n",
    "if not model_file.exists():\n",
    "    raise FileNotFoundError(f\"Model fayli topilmadi: {model_file}. Avval train.ipynb ni ishga tushiring!\")\n",
    "\n",
    "if not encoders_file.exists():\n",
    "    raise FileNotFoundError(f\"Encoders fayli topilmadi: {encoders_file}. Avval train.ipynb ni ishga tushiring!\")\n",
    "\n",
    "if not categorical_file.exists():\n",
    "    raise FileNotFoundError(f\"Categorical columns fayli topilmadi: {categorical_file}. Avval train.ipynb ni ishga tushiring!\")\n",
    "\n",
    "if not feature_columns_file.exists():\n",
    "    raise FileNotFoundError(f\"Feature columns fayli topilmadi: {feature_columns_file}. Avval train.ipynb ni ishga tushiring!\")\n",
    "\n",
    "# Fayllarni yuklash\n",
    "with open(model_file, 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "with open(encoders_file, 'rb') as f:\n",
    "    label_encoders = pickle.load(f)\n",
    "\n",
    "with open(categorical_file, 'rb') as f:\n",
    "    categorical_columns = pickle.load(f)\n",
    "\n",
    "with open(feature_columns_file, 'rb') as f:\n",
    "    feature_columns = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "18c72f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 2. YANGI DATASETNI YUKLASH\n",
    "# ============================================\n",
    "\n",
    "# Yangi dataset fayl yo'li (o'zgartiring)\n",
    "new_dataset_path = 'dataset_for_models.csv'  # ← Bu yerga yangi dataset yo'lini kiriting\n",
    "\n",
    "# Datasetni yuklash\n",
    "df_new = pd.read_csv(new_dataset_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5a5eae37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 3. FEATURELARNI TAYYORLASH\n",
    "# ============================================\n",
    "\n",
    "def prepare_features(df, target_column='default'):\n",
    "    \"\"\"\n",
    "    Datasetdan kerakli va kerak bo'lmagan ustunlarni ajratib oladi.\n",
    "    Target ustuni bo'lmasa ham ishlaydi.\n",
    "    \"\"\"\n",
    "    # ID ustunlar (model uchun kerak emas)\n",
    "    id_columns = ['customer_ref', 'application_id']\n",
    "    \n",
    "    # Kerak bo'lmagan ustunlar (identifikatorlar yoki foydasiz)\n",
    "    unnecessary_columns = ['loan_officer_id', 'previous_zip_code', 'referral_code']\n",
    "    \n",
    "    # Barcha olib tashlash kerak bo'lgan ustunlar\n",
    "    columns_to_drop = id_columns + unnecessary_columns\n",
    "    \n",
    "    # Target ustunni qo'shish (agar mavjud bo'lsa)\n",
    "    if target_column and target_column in df.columns:\n",
    "        columns_to_drop.append(target_column)\n",
    "    \n",
    "    # Faqat mavjud ustunlarni olib tashlash\n",
    "    columns_to_drop = [col for col in columns_to_drop if col in df.columns]\n",
    "    \n",
    "    # Feature ustunlar (X)\n",
    "    X = df.drop(columns=columns_to_drop, errors='ignore')\n",
    "    \n",
    "    return X\n",
    "\n",
    "# Featurelarni tayyorlash\n",
    "X_new = prepare_features(df_new, target_column='default')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f192182a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 4. CATEGORICAL USTUNLARNI ENCODE QILISH\n",
    "# ============================================\n",
    "\n",
    "X_new_encoded = X_new.copy()\n",
    "\n",
    "for col in categorical_columns:\n",
    "    if col in X_new_encoded.columns:\n",
    "        try:\n",
    "            encoded_values = label_encoders[col].transform(X_new[col].astype(str))\n",
    "            X_new_encoded[col] = pd.Series(encoded_values, dtype='int64', index=X_new_encoded.index)\n",
    "        except ValueError:\n",
    "            max_encoded = len(label_encoders[col].classes_) - 1\n",
    "            encoded_values = X_new[col].astype(str).apply(\n",
    "                lambda x: label_encoders[col].transform([x])[0] \n",
    "                if x in label_encoders[col].classes_ \n",
    "                else max_encoded + 1\n",
    "            )\n",
    "            X_new_encoded[col] = pd.Series(encoded_values, dtype='int64', index=X_new_encoded.index)\n",
    "\n",
    "# Qolgan object type ustunlarni olib tashlash\n",
    "remaining_object_cols = X_new_encoded.select_dtypes(include=['object']).columns.tolist()\n",
    "if remaining_object_cols:\n",
    "    X_new_encoded = X_new_encoded.drop(columns=remaining_object_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f1499105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 5. FEATURELARNI MODEL UCHUN TAYYORLASH\n",
    "# ============================================\n",
    "\n",
    "# Training da bo'lgan barcha feature ustunlarni ta'minlash\n",
    "X_final = pd.DataFrame(index=X_new_encoded.index)\n",
    "\n",
    "for col in feature_columns:\n",
    "    if col in X_new_encoded.columns:\n",
    "        X_final[col] = X_new_encoded[col].astype('float64')\n",
    "    else:\n",
    "        X_final[col] = 0.0\n",
    "\n",
    "# Ustunlar tartibini training dagi kabi qilish\n",
    "X_final = X_final[feature_columns]\n",
    "\n",
    "# ============================================\n",
    "# 6. PREDICT QILISH\n",
    "# ============================================\n",
    "\n",
    "new_proba = model.predict_proba(X_final)[:, 1]\n",
    "new_pred = (new_proba >= 0.5).astype(int)  # Prob >= 0.5 → default = 1\n",
    "\n",
    "# ============================================\n",
    "# 7. MODEL BAHOLASH (agar default ustuni bo'lsa)\n",
    "# ============================================\n",
    "\n",
    "if 'default' in df_new.columns:\n",
    "    y_true = df_new['default'].values\n",
    "    auc_score = roc_auc_score(y_true, new_proba)\n",
    "    accuracy = accuracy_score(y_true, new_pred)\n",
    "    f1 = f1_score(y_true, new_pred)\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"MODEL NATIJALARI\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"ROC-AUC Score: {auc_score:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_true, new_pred))\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, new_pred))\n",
    "    print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6ea71e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 8. NATIJALARNI SAQLASH\n",
    "# ============================================\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'customer_id': df_new['customer_ref'].values.astype(int),\n",
    "    'prob': new_proba.round(5),\n",
    "    'default': new_pred\n",
    "})\n",
    "\n",
    "output_file = model_folder / 'results.csv'\n",
    "results_df.to_csv(output_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8864f099",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
